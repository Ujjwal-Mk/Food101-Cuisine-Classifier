{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3050 Laptop GPU, compute capability 8.6\n",
      "<Policy \"mixed_float16\">\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import tensorflow as tf\n",
    "from helper_functions import *\n",
    "importTensorflow(memory=4090)\n",
    "precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 101000 files belonging to 14 classes.\n",
      "Using 70700 files for training.\n",
      "Using 30300 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = tf.keras.utils.image_dataset_from_directory('food-101/cuisines/',\n",
    "                                                        image_size=(512, 512),\n",
    "                                                        validation_split = 0.3,\n",
    "                                                        subset = 'both',\n",
    "                                                        seed = 42,\n",
    "                                                        batch_size=64,\n",
    "                                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 14\n",
    "def preprocess_img(image, label):\n",
    "    return tf.cast(image, tf.float32), label\n",
    "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_data = train_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_data = test_data.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "input_shape = (512, 512, 3)\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B3(include_top=False)\n",
    "base_model.trainable = False\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "# x = data_aug(inputs, training=False)\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "x = layers.Dense(classes)(x)\n",
    "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch:3e-3/10**(epoch/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710840064.170330   14197 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105/1105 [==============================] - 695s 613ms/step - loss: 1.1284 - accuracy: 0.6092 - val_loss: 0.8828 - val_accuracy: 0.7001 - lr: 0.0030\n",
      "Epoch 2/5\n",
      "1105/1105 [==============================] - 669s 605ms/step - loss: 0.8498 - accuracy: 0.7061 - val_loss: 0.7918 - val_accuracy: 0.7306 - lr: 0.0019\n",
      "Epoch 3/5\n",
      "1105/1105 [==============================] - 669s 605ms/step - loss: 0.7368 - accuracy: 0.7451 - val_loss: 0.7468 - val_accuracy: 0.7488 - lr: 0.0012\n",
      "Epoch 4/5\n",
      "1105/1105 [==============================] - 667s 603ms/step - loss: 0.6667 - accuracy: 0.7681 - val_loss: 0.7289 - val_accuracy: 0.7553 - lr: 7.5357e-04\n",
      "Epoch 5/5\n",
      "1105/1105 [==============================] - 665s 602ms/step - loss: 0.6190 - accuracy: 0.7851 - val_loss: 0.7116 - val_accuracy: 0.7598 - lr: 4.7547e-04\n"
     ]
    }
   ],
   "source": [
    "history_101_food_classes_feature_extract = model.fit(train_data,\n",
    "                                                     epochs=5,\n",
    "                                                     steps_per_epoch=len(train_data),\n",
    "                                                     validation_data=test_data,\n",
    "                                                     validation_steps=int(0.2 * len(test_data)),\n",
    "                                                     callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 268s 565ms/step - loss: 0.7323 - accuracy: 0.7555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7323012351989746, 0.75547856092453]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cuisine_feature_extractor/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cuisine_feature_extractor/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('cuisine_feature_extractor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 512, 512, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetv2-b3 (Functio  (None, None, None, 1536   12930622  \n",
      " nal)                        )                                   \n",
      "                                                                 \n",
      " pooling_layer (GlobalAvera  (None, 1536)              0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               196736    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 14)                1806      \n",
      "                                                                 \n",
      " softmax_float32 (Activatio  (None, 14)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13129164 (50.08 MB)\n",
      "Trainable params: 198542 (775.55 KB)\n",
      "Non-trainable params: 12930622 (49.33 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_saved_model = tf.keras.models.load_model('cuisine_feature_extractor')\n",
    "loaded_saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_layer True\n",
      "1 efficientnetv2-b3 False\n",
      "2 pooling_layer True\n",
      "3 dense True\n",
      "4 dropout True\n",
      "5 dense_1 True\n",
      "6 softmax_float32 True\n"
     ]
    }
   ],
   "source": [
    "# fine tuning\n",
    "for i, layer in enumerate(loaded_saved_model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 True\n",
      "1 rescaling False\n",
      "2 normalization False\n",
      "3 stem_conv False\n",
      "4 stem_bn False\n",
      "5 stem_activation False\n",
      "6 block1a_project_conv False\n",
      "7 block1a_project_bn False\n",
      "8 block1a_project_activation False\n",
      "9 block1b_project_conv False\n",
      "10 block1b_project_bn False\n",
      "11 block1b_project_activation False\n",
      "12 block1b_drop False\n",
      "13 block1b_add False\n",
      "14 block2a_expand_conv False\n",
      "15 block2a_expand_bn False\n",
      "16 block2a_expand_activation False\n",
      "17 block2a_project_conv False\n",
      "18 block2a_project_bn False\n",
      "19 block2b_expand_conv False\n",
      "20 block2b_expand_bn False\n",
      "21 block2b_expand_activation False\n",
      "22 block2b_project_conv False\n",
      "23 block2b_project_bn False\n",
      "24 block2b_drop False\n",
      "25 block2b_add False\n",
      "26 block2c_expand_conv False\n",
      "27 block2c_expand_bn False\n",
      "28 block2c_expand_activation False\n",
      "29 block2c_project_conv False\n",
      "30 block2c_project_bn False\n",
      "31 block2c_drop False\n",
      "32 block2c_add False\n",
      "33 block3a_expand_conv False\n",
      "34 block3a_expand_bn False\n",
      "35 block3a_expand_activation False\n",
      "36 block3a_project_conv False\n",
      "37 block3a_project_bn False\n",
      "38 block3b_expand_conv False\n",
      "39 block3b_expand_bn False\n",
      "40 block3b_expand_activation False\n",
      "41 block3b_project_conv False\n",
      "42 block3b_project_bn False\n",
      "43 block3b_drop False\n",
      "44 block3b_add False\n",
      "45 block3c_expand_conv False\n",
      "46 block3c_expand_bn False\n",
      "47 block3c_expand_activation False\n",
      "48 block3c_project_conv False\n",
      "49 block3c_project_bn False\n",
      "50 block3c_drop False\n",
      "51 block3c_add False\n",
      "52 block4a_expand_conv False\n",
      "53 block4a_expand_bn False\n",
      "54 block4a_expand_activation False\n",
      "55 block4a_dwconv2 False\n",
      "56 block4a_bn False\n",
      "57 block4a_activation False\n",
      "58 block4a_se_squeeze False\n",
      "59 block4a_se_reshape False\n",
      "60 block4a_se_reduce False\n",
      "61 block4a_se_expand False\n",
      "62 block4a_se_excite False\n",
      "63 block4a_project_conv False\n",
      "64 block4a_project_bn False\n",
      "65 block4b_expand_conv False\n",
      "66 block4b_expand_bn False\n",
      "67 block4b_expand_activation False\n",
      "68 block4b_dwconv2 False\n",
      "69 block4b_bn False\n",
      "70 block4b_activation False\n",
      "71 block4b_se_squeeze False\n",
      "72 block4b_se_reshape False\n",
      "73 block4b_se_reduce False\n",
      "74 block4b_se_expand False\n",
      "75 block4b_se_excite False\n",
      "76 block4b_project_conv False\n",
      "77 block4b_project_bn False\n",
      "78 block4b_drop False\n",
      "79 block4b_add False\n",
      "80 block4c_expand_conv False\n",
      "81 block4c_expand_bn False\n",
      "82 block4c_expand_activation False\n",
      "83 block4c_dwconv2 False\n",
      "84 block4c_bn False\n",
      "85 block4c_activation False\n",
      "86 block4c_se_squeeze False\n",
      "87 block4c_se_reshape False\n",
      "88 block4c_se_reduce False\n",
      "89 block4c_se_expand False\n",
      "90 block4c_se_excite False\n",
      "91 block4c_project_conv False\n",
      "92 block4c_project_bn False\n",
      "93 block4c_drop False\n",
      "94 block4c_add False\n",
      "95 block4d_expand_conv False\n",
      "96 block4d_expand_bn False\n",
      "97 block4d_expand_activation False\n",
      "98 block4d_dwconv2 False\n",
      "99 block4d_bn False\n",
      "100 block4d_activation False\n",
      "101 block4d_se_squeeze False\n",
      "102 block4d_se_reshape False\n",
      "103 block4d_se_reduce False\n",
      "104 block4d_se_expand False\n",
      "105 block4d_se_excite False\n",
      "106 block4d_project_conv False\n",
      "107 block4d_project_bn False\n",
      "108 block4d_drop False\n",
      "109 block4d_add False\n",
      "110 block4e_expand_conv False\n",
      "111 block4e_expand_bn False\n",
      "112 block4e_expand_activation False\n",
      "113 block4e_dwconv2 False\n",
      "114 block4e_bn False\n",
      "115 block4e_activation False\n",
      "116 block4e_se_squeeze False\n",
      "117 block4e_se_reshape False\n",
      "118 block4e_se_reduce False\n",
      "119 block4e_se_expand False\n",
      "120 block4e_se_excite False\n",
      "121 block4e_project_conv False\n",
      "122 block4e_project_bn False\n",
      "123 block4e_drop False\n",
      "124 block4e_add False\n",
      "125 block5a_expand_conv False\n",
      "126 block5a_expand_bn False\n",
      "127 block5a_expand_activation False\n",
      "128 block5a_dwconv2 False\n",
      "129 block5a_bn False\n",
      "130 block5a_activation False\n",
      "131 block5a_se_squeeze False\n",
      "132 block5a_se_reshape False\n",
      "133 block5a_se_reduce False\n",
      "134 block5a_se_expand False\n",
      "135 block5a_se_excite False\n",
      "136 block5a_project_conv False\n",
      "137 block5a_project_bn False\n",
      "138 block5b_expand_conv False\n",
      "139 block5b_expand_bn False\n",
      "140 block5b_expand_activation False\n",
      "141 block5b_dwconv2 False\n",
      "142 block5b_bn False\n",
      "143 block5b_activation False\n",
      "144 block5b_se_squeeze False\n",
      "145 block5b_se_reshape False\n",
      "146 block5b_se_reduce False\n",
      "147 block5b_se_expand False\n",
      "148 block5b_se_excite False\n",
      "149 block5b_project_conv False\n",
      "150 block5b_project_bn False\n",
      "151 block5b_drop False\n",
      "152 block5b_add False\n",
      "153 block5c_expand_conv False\n",
      "154 block5c_expand_bn False\n",
      "155 block5c_expand_activation False\n",
      "156 block5c_dwconv2 False\n",
      "157 block5c_bn False\n",
      "158 block5c_activation False\n",
      "159 block5c_se_squeeze False\n",
      "160 block5c_se_reshape False\n",
      "161 block5c_se_reduce False\n",
      "162 block5c_se_expand False\n",
      "163 block5c_se_excite False\n",
      "164 block5c_project_conv False\n",
      "165 block5c_project_bn False\n",
      "166 block5c_drop False\n",
      "167 block5c_add False\n",
      "168 block5d_expand_conv False\n",
      "169 block5d_expand_bn False\n",
      "170 block5d_expand_activation False\n",
      "171 block5d_dwconv2 False\n",
      "172 block5d_bn False\n",
      "173 block5d_activation False\n",
      "174 block5d_se_squeeze False\n",
      "175 block5d_se_reshape False\n",
      "176 block5d_se_reduce False\n",
      "177 block5d_se_expand False\n",
      "178 block5d_se_excite False\n",
      "179 block5d_project_conv False\n",
      "180 block5d_project_bn False\n",
      "181 block5d_drop False\n",
      "182 block5d_add False\n",
      "183 block5e_expand_conv False\n",
      "184 block5e_expand_bn False\n",
      "185 block5e_expand_activation False\n",
      "186 block5e_dwconv2 False\n",
      "187 block5e_bn False\n",
      "188 block5e_activation False\n",
      "189 block5e_se_squeeze False\n",
      "190 block5e_se_reshape False\n",
      "191 block5e_se_reduce False\n",
      "192 block5e_se_expand False\n",
      "193 block5e_se_excite False\n",
      "194 block5e_project_conv False\n",
      "195 block5e_project_bn False\n",
      "196 block5e_drop False\n",
      "197 block5e_add False\n",
      "198 block5f_expand_conv False\n",
      "199 block5f_expand_bn False\n",
      "200 block5f_expand_activation False\n",
      "201 block5f_dwconv2 False\n",
      "202 block5f_bn False\n",
      "203 block5f_activation False\n",
      "204 block5f_se_squeeze False\n",
      "205 block5f_se_reshape False\n",
      "206 block5f_se_reduce False\n",
      "207 block5f_se_expand False\n",
      "208 block5f_se_excite False\n",
      "209 block5f_project_conv False\n",
      "210 block5f_project_bn False\n",
      "211 block5f_drop False\n",
      "212 block5f_add False\n",
      "213 block5g_expand_conv False\n",
      "214 block5g_expand_bn False\n",
      "215 block5g_expand_activation False\n",
      "216 block5g_dwconv2 False\n",
      "217 block5g_bn False\n",
      "218 block5g_activation False\n",
      "219 block5g_se_squeeze False\n",
      "220 block5g_se_reshape False\n",
      "221 block5g_se_reduce False\n",
      "222 block5g_se_expand False\n",
      "223 block5g_se_excite False\n",
      "224 block5g_project_conv False\n",
      "225 block5g_project_bn False\n",
      "226 block5g_drop False\n",
      "227 block5g_add False\n",
      "228 block6a_expand_conv False\n",
      "229 block6a_expand_bn False\n",
      "230 block6a_expand_activation False\n",
      "231 block6a_dwconv2 False\n",
      "232 block6a_bn False\n",
      "233 block6a_activation False\n",
      "234 block6a_se_squeeze False\n",
      "235 block6a_se_reshape False\n",
      "236 block6a_se_reduce False\n",
      "237 block6a_se_expand False\n",
      "238 block6a_se_excite False\n",
      "239 block6a_project_conv False\n",
      "240 block6a_project_bn False\n",
      "241 block6b_expand_conv False\n",
      "242 block6b_expand_bn False\n",
      "243 block6b_expand_activation False\n",
      "244 block6b_dwconv2 False\n",
      "245 block6b_bn False\n",
      "246 block6b_activation False\n",
      "247 block6b_se_squeeze False\n",
      "248 block6b_se_reshape False\n",
      "249 block6b_se_reduce False\n",
      "250 block6b_se_expand False\n",
      "251 block6b_se_excite False\n",
      "252 block6b_project_conv False\n",
      "253 block6b_project_bn False\n",
      "254 block6b_drop False\n",
      "255 block6b_add False\n",
      "256 block6c_expand_conv False\n",
      "257 block6c_expand_bn False\n",
      "258 block6c_expand_activation False\n",
      "259 block6c_dwconv2 False\n",
      "260 block6c_bn False\n",
      "261 block6c_activation False\n",
      "262 block6c_se_squeeze False\n",
      "263 block6c_se_reshape False\n",
      "264 block6c_se_reduce False\n",
      "265 block6c_se_expand False\n",
      "266 block6c_se_excite False\n",
      "267 block6c_project_conv False\n",
      "268 block6c_project_bn False\n",
      "269 block6c_drop False\n",
      "270 block6c_add False\n",
      "271 block6d_expand_conv False\n",
      "272 block6d_expand_bn False\n",
      "273 block6d_expand_activation False\n",
      "274 block6d_dwconv2 False\n",
      "275 block6d_bn False\n",
      "276 block6d_activation False\n",
      "277 block6d_se_squeeze False\n",
      "278 block6d_se_reshape False\n",
      "279 block6d_se_reduce False\n",
      "280 block6d_se_expand False\n",
      "281 block6d_se_excite False\n",
      "282 block6d_project_conv False\n",
      "283 block6d_project_bn False\n",
      "284 block6d_drop False\n",
      "285 block6d_add False\n",
      "286 block6e_expand_conv False\n",
      "287 block6e_expand_bn False\n",
      "288 block6e_expand_activation False\n",
      "289 block6e_dwconv2 False\n",
      "290 block6e_bn False\n",
      "291 block6e_activation False\n",
      "292 block6e_se_squeeze False\n",
      "293 block6e_se_reshape False\n",
      "294 block6e_se_reduce False\n",
      "295 block6e_se_expand False\n",
      "296 block6e_se_excite False\n",
      "297 block6e_project_conv False\n",
      "298 block6e_project_bn False\n",
      "299 block6e_drop False\n",
      "300 block6e_add False\n",
      "301 block6f_expand_conv False\n",
      "302 block6f_expand_bn False\n",
      "303 block6f_expand_activation False\n",
      "304 block6f_dwconv2 False\n",
      "305 block6f_bn False\n",
      "306 block6f_activation False\n",
      "307 block6f_se_squeeze False\n",
      "308 block6f_se_reshape False\n",
      "309 block6f_se_reduce False\n",
      "310 block6f_se_expand False\n",
      "311 block6f_se_excite False\n",
      "312 block6f_project_conv False\n",
      "313 block6f_project_bn False\n",
      "314 block6f_drop False\n",
      "315 block6f_add False\n",
      "316 block6g_expand_conv False\n",
      "317 block6g_expand_bn False\n",
      "318 block6g_expand_activation False\n",
      "319 block6g_dwconv2 False\n",
      "320 block6g_bn False\n",
      "321 block6g_activation False\n",
      "322 block6g_se_squeeze False\n",
      "323 block6g_se_reshape False\n",
      "324 block6g_se_reduce False\n",
      "325 block6g_se_expand False\n",
      "326 block6g_se_excite False\n",
      "327 block6g_project_conv False\n",
      "328 block6g_project_bn False\n",
      "329 block6g_drop False\n",
      "330 block6g_add False\n",
      "331 block6h_expand_conv False\n",
      "332 block6h_expand_bn False\n",
      "333 block6h_expand_activation False\n",
      "334 block6h_dwconv2 False\n",
      "335 block6h_bn False\n",
      "336 block6h_activation False\n",
      "337 block6h_se_squeeze False\n",
      "338 block6h_se_reshape False\n",
      "339 block6h_se_reduce False\n",
      "340 block6h_se_expand False\n",
      "341 block6h_se_excite False\n",
      "342 block6h_project_conv False\n",
      "343 block6h_project_bn False\n",
      "344 block6h_drop False\n",
      "345 block6h_add False\n",
      "346 block6i_expand_conv False\n",
      "347 block6i_expand_bn False\n",
      "348 block6i_expand_activation False\n",
      "349 block6i_dwconv2 False\n",
      "350 block6i_bn False\n",
      "351 block6i_activation False\n",
      "352 block6i_se_squeeze False\n",
      "353 block6i_se_reshape False\n",
      "354 block6i_se_reduce False\n",
      "355 block6i_se_expand False\n",
      "356 block6i_se_excite False\n",
      "357 block6i_project_conv False\n",
      "358 block6i_project_bn False\n",
      "359 block6i_drop False\n",
      "360 block6i_add False\n",
      "361 block6j_expand_conv False\n",
      "362 block6j_expand_bn False\n",
      "363 block6j_expand_activation False\n",
      "364 block6j_dwconv2 False\n",
      "365 block6j_bn False\n",
      "366 block6j_activation False\n",
      "367 block6j_se_squeeze False\n",
      "368 block6j_se_reshape False\n",
      "369 block6j_se_reduce False\n",
      "370 block6j_se_expand False\n",
      "371 block6j_se_excite False\n",
      "372 block6j_project_conv False\n",
      "373 block6j_project_bn False\n",
      "374 block6j_drop False\n",
      "375 block6j_add False\n",
      "376 block6k_expand_conv False\n",
      "377 block6k_expand_bn False\n",
      "378 block6k_expand_activation False\n",
      "379 block6k_dwconv2 False\n",
      "380 block6k_bn False\n",
      "381 block6k_activation False\n",
      "382 block6k_se_squeeze False\n",
      "383 block6k_se_reshape False\n",
      "384 block6k_se_reduce False\n",
      "385 block6k_se_expand False\n",
      "386 block6k_se_excite False\n",
      "387 block6k_project_conv False\n",
      "388 block6k_project_bn False\n",
      "389 block6k_drop False\n",
      "390 block6k_add False\n",
      "391 block6l_expand_conv False\n",
      "392 block6l_expand_bn False\n",
      "393 block6l_expand_activation False\n",
      "394 block6l_dwconv2 False\n",
      "395 block6l_bn False\n",
      "396 block6l_activation False\n",
      "397 block6l_se_squeeze False\n",
      "398 block6l_se_reshape False\n",
      "399 block6l_se_reduce False\n",
      "400 block6l_se_expand False\n",
      "401 block6l_se_excite False\n",
      "402 block6l_project_conv False\n",
      "403 block6l_project_bn False\n",
      "404 block6l_drop False\n",
      "405 block6l_add False\n",
      "406 top_conv False\n",
      "407 top_bn False\n",
      "408 top_activation False\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(loaded_saved_model.layers[1].layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 rescaling False\n",
      "2 normalization False\n",
      "3 stem_conv False\n",
      "4 stem_bn False\n",
      "5 stem_activation False\n",
      "6 block1a_project_conv False\n",
      "7 block1a_project_bn False\n",
      "8 block1a_project_activation False\n",
      "9 block1b_project_conv False\n",
      "10 block1b_project_bn False\n",
      "11 block1b_project_activation False\n",
      "12 block1b_drop False\n",
      "13 block1b_add False\n",
      "14 block2a_expand_conv False\n",
      "15 block2a_expand_bn False\n",
      "16 block2a_expand_activation False\n",
      "17 block2a_project_conv False\n",
      "18 block2a_project_bn False\n",
      "19 block2b_expand_conv False\n",
      "20 block2b_expand_bn False\n",
      "21 block2b_expand_activation False\n",
      "22 block2b_project_conv False\n",
      "23 block2b_project_bn False\n",
      "24 block2b_drop False\n",
      "25 block2b_add False\n",
      "26 block2c_expand_conv False\n",
      "27 block2c_expand_bn False\n",
      "28 block2c_expand_activation False\n",
      "29 block2c_project_conv False\n",
      "30 block2c_project_bn False\n",
      "31 block2c_drop False\n",
      "32 block2c_add False\n",
      "33 block3a_expand_conv False\n",
      "34 block3a_expand_bn False\n",
      "35 block3a_expand_activation False\n",
      "36 block3a_project_conv False\n",
      "37 block3a_project_bn False\n",
      "38 block3b_expand_conv False\n",
      "39 block3b_expand_bn False\n",
      "40 block3b_expand_activation False\n",
      "41 block3b_project_conv False\n",
      "42 block3b_project_bn False\n",
      "43 block3b_drop False\n",
      "44 block3b_add False\n",
      "45 block3c_expand_conv False\n",
      "46 block3c_expand_bn False\n",
      "47 block3c_expand_activation False\n",
      "48 block3c_project_conv False\n",
      "49 block3c_project_bn False\n",
      "50 block3c_drop False\n",
      "51 block3c_add False\n",
      "52 block4a_expand_conv False\n",
      "53 block4a_expand_bn False\n",
      "54 block4a_expand_activation False\n",
      "55 block4a_dwconv2 False\n",
      "56 block4a_bn False\n",
      "57 block4a_activation False\n",
      "58 block4a_se_squeeze False\n",
      "59 block4a_se_reshape False\n",
      "60 block4a_se_reduce False\n",
      "61 block4a_se_expand False\n",
      "62 block4a_se_excite False\n",
      "63 block4a_project_conv False\n",
      "64 block4a_project_bn False\n",
      "65 block4b_expand_conv False\n",
      "66 block4b_expand_bn False\n",
      "67 block4b_expand_activation False\n",
      "68 block4b_dwconv2 False\n",
      "69 block4b_bn False\n",
      "70 block4b_activation False\n",
      "71 block4b_se_squeeze False\n",
      "72 block4b_se_reshape False\n",
      "73 block4b_se_reduce False\n",
      "74 block4b_se_expand False\n",
      "75 block4b_se_excite False\n",
      "76 block4b_project_conv False\n",
      "77 block4b_project_bn False\n",
      "78 block4b_drop False\n",
      "79 block4b_add False\n",
      "80 block4c_expand_conv False\n",
      "81 block4c_expand_bn False\n",
      "82 block4c_expand_activation False\n",
      "83 block4c_dwconv2 False\n",
      "84 block4c_bn False\n",
      "85 block4c_activation False\n",
      "86 block4c_se_squeeze False\n",
      "87 block4c_se_reshape False\n",
      "88 block4c_se_reduce False\n",
      "89 block4c_se_expand False\n",
      "90 block4c_se_excite False\n",
      "91 block4c_project_conv False\n",
      "92 block4c_project_bn False\n",
      "93 block4c_drop False\n",
      "94 block4c_add False\n",
      "95 block4d_expand_conv False\n",
      "96 block4d_expand_bn False\n",
      "97 block4d_expand_activation False\n",
      "98 block4d_dwconv2 False\n",
      "99 block4d_bn False\n",
      "100 block4d_activation False\n",
      "101 block4d_se_squeeze False\n",
      "102 block4d_se_reshape False\n",
      "103 block4d_se_reduce False\n",
      "104 block4d_se_expand False\n",
      "105 block4d_se_excite False\n",
      "106 block4d_project_conv False\n",
      "107 block4d_project_bn False\n",
      "108 block4d_drop False\n",
      "109 block4d_add False\n",
      "110 block4e_expand_conv False\n",
      "111 block4e_expand_bn False\n",
      "112 block4e_expand_activation False\n",
      "113 block4e_dwconv2 False\n",
      "114 block4e_bn False\n",
      "115 block4e_activation False\n",
      "116 block4e_se_squeeze False\n",
      "117 block4e_se_reshape False\n",
      "118 block4e_se_reduce False\n",
      "119 block4e_se_expand False\n",
      "120 block4e_se_excite False\n",
      "121 block4e_project_conv False\n",
      "122 block4e_project_bn False\n",
      "123 block4e_drop False\n",
      "124 block4e_add False\n",
      "125 block5a_expand_conv False\n",
      "126 block5a_expand_bn False\n",
      "127 block5a_expand_activation False\n",
      "128 block5a_dwconv2 False\n",
      "129 block5a_bn False\n",
      "130 block5a_activation False\n",
      "131 block5a_se_squeeze False\n",
      "132 block5a_se_reshape False\n",
      "133 block5a_se_reduce False\n",
      "134 block5a_se_expand False\n",
      "135 block5a_se_excite False\n",
      "136 block5a_project_conv False\n",
      "137 block5a_project_bn False\n",
      "138 block5b_expand_conv False\n",
      "139 block5b_expand_bn False\n",
      "140 block5b_expand_activation False\n",
      "141 block5b_dwconv2 False\n",
      "142 block5b_bn False\n",
      "143 block5b_activation False\n",
      "144 block5b_se_squeeze False\n",
      "145 block5b_se_reshape False\n",
      "146 block5b_se_reduce False\n",
      "147 block5b_se_expand False\n",
      "148 block5b_se_excite False\n",
      "149 block5b_project_conv False\n",
      "150 block5b_project_bn False\n",
      "151 block5b_drop False\n",
      "152 block5b_add False\n",
      "153 block5c_expand_conv False\n",
      "154 block5c_expand_bn False\n",
      "155 block5c_expand_activation False\n",
      "156 block5c_dwconv2 False\n",
      "157 block5c_bn False\n",
      "158 block5c_activation False\n",
      "159 block5c_se_squeeze False\n",
      "160 block5c_se_reshape False\n",
      "161 block5c_se_reduce False\n",
      "162 block5c_se_expand False\n",
      "163 block5c_se_excite False\n",
      "164 block5c_project_conv False\n",
      "165 block5c_project_bn False\n",
      "166 block5c_drop False\n",
      "167 block5c_add False\n",
      "168 block5d_expand_conv False\n",
      "169 block5d_expand_bn False\n",
      "170 block5d_expand_activation False\n",
      "171 block5d_dwconv2 False\n",
      "172 block5d_bn False\n",
      "173 block5d_activation False\n",
      "174 block5d_se_squeeze False\n",
      "175 block5d_se_reshape False\n",
      "176 block5d_se_reduce False\n",
      "177 block5d_se_expand False\n",
      "178 block5d_se_excite False\n",
      "179 block5d_project_conv False\n",
      "180 block5d_project_bn False\n",
      "181 block5d_drop False\n",
      "182 block5d_add False\n",
      "183 block5e_expand_conv False\n",
      "184 block5e_expand_bn False\n",
      "185 block5e_expand_activation False\n",
      "186 block5e_dwconv2 False\n",
      "187 block5e_bn False\n",
      "188 block5e_activation False\n",
      "189 block5e_se_squeeze False\n",
      "190 block5e_se_reshape False\n",
      "191 block5e_se_reduce False\n",
      "192 block5e_se_expand False\n",
      "193 block5e_se_excite False\n",
      "194 block5e_project_conv False\n",
      "195 block5e_project_bn False\n",
      "196 block5e_drop False\n",
      "197 block5e_add False\n",
      "198 block5f_expand_conv False\n",
      "199 block5f_expand_bn False\n",
      "200 block5f_expand_activation False\n",
      "201 block5f_dwconv2 False\n",
      "202 block5f_bn False\n",
      "203 block5f_activation False\n",
      "204 block5f_se_squeeze False\n",
      "205 block5f_se_reshape False\n",
      "206 block5f_se_reduce False\n",
      "207 block5f_se_expand False\n",
      "208 block5f_se_excite False\n",
      "209 block5f_project_conv False\n",
      "210 block5f_project_bn False\n",
      "211 block5f_drop False\n",
      "212 block5f_add False\n",
      "213 block5g_expand_conv False\n",
      "214 block5g_expand_bn False\n",
      "215 block5g_expand_activation False\n",
      "216 block5g_dwconv2 False\n",
      "217 block5g_bn False\n",
      "218 block5g_activation False\n",
      "219 block5g_se_squeeze False\n",
      "220 block5g_se_reshape False\n",
      "221 block5g_se_reduce False\n",
      "222 block5g_se_expand False\n",
      "223 block5g_se_excite False\n",
      "224 block5g_project_conv False\n",
      "225 block5g_project_bn False\n",
      "226 block5g_drop False\n",
      "227 block5g_add False\n",
      "228 block6a_expand_conv False\n",
      "229 block6a_expand_bn False\n",
      "230 block6a_expand_activation False\n",
      "231 block6a_dwconv2 False\n",
      "232 block6a_bn False\n",
      "233 block6a_activation False\n",
      "234 block6a_se_squeeze False\n",
      "235 block6a_se_reshape False\n",
      "236 block6a_se_reduce False\n",
      "237 block6a_se_expand False\n",
      "238 block6a_se_excite False\n",
      "239 block6a_project_conv False\n",
      "240 block6a_project_bn False\n",
      "241 block6b_expand_conv False\n",
      "242 block6b_expand_bn False\n",
      "243 block6b_expand_activation False\n",
      "244 block6b_dwconv2 False\n",
      "245 block6b_bn False\n",
      "246 block6b_activation False\n",
      "247 block6b_se_squeeze False\n",
      "248 block6b_se_reshape False\n",
      "249 block6b_se_reduce False\n",
      "250 block6b_se_expand False\n",
      "251 block6b_se_excite False\n",
      "252 block6b_project_conv False\n",
      "253 block6b_project_bn False\n",
      "254 block6b_drop False\n",
      "255 block6b_add False\n",
      "256 block6c_expand_conv False\n",
      "257 block6c_expand_bn False\n",
      "258 block6c_expand_activation False\n",
      "259 block6c_dwconv2 False\n",
      "260 block6c_bn False\n",
      "261 block6c_activation False\n",
      "262 block6c_se_squeeze False\n",
      "263 block6c_se_reshape False\n",
      "264 block6c_se_reduce False\n",
      "265 block6c_se_expand False\n",
      "266 block6c_se_excite False\n",
      "267 block6c_project_conv False\n",
      "268 block6c_project_bn False\n",
      "269 block6c_drop False\n",
      "270 block6c_add False\n",
      "271 block6d_expand_conv False\n",
      "272 block6d_expand_bn False\n",
      "273 block6d_expand_activation False\n",
      "274 block6d_dwconv2 False\n",
      "275 block6d_bn False\n",
      "276 block6d_activation False\n",
      "277 block6d_se_squeeze False\n",
      "278 block6d_se_reshape False\n",
      "279 block6d_se_reduce False\n",
      "280 block6d_se_expand False\n",
      "281 block6d_se_excite False\n",
      "282 block6d_project_conv False\n",
      "283 block6d_project_bn False\n",
      "284 block6d_drop False\n",
      "285 block6d_add False\n",
      "286 block6e_expand_conv False\n",
      "287 block6e_expand_bn False\n",
      "288 block6e_expand_activation False\n",
      "289 block6e_dwconv2 False\n",
      "290 block6e_bn False\n",
      "291 block6e_activation False\n",
      "292 block6e_se_squeeze False\n",
      "293 block6e_se_reshape False\n",
      "294 block6e_se_reduce False\n",
      "295 block6e_se_expand False\n",
      "296 block6e_se_excite False\n",
      "297 block6e_project_conv False\n",
      "298 block6e_project_bn False\n",
      "299 block6e_drop False\n",
      "300 block6e_add False\n",
      "301 block6f_expand_conv False\n",
      "302 block6f_expand_bn False\n",
      "303 block6f_expand_activation False\n",
      "304 block6f_dwconv2 False\n",
      "305 block6f_bn False\n",
      "306 block6f_activation False\n",
      "307 block6f_se_squeeze False\n",
      "308 block6f_se_reshape False\n",
      "309 block6f_se_reduce False\n",
      "310 block6f_se_expand False\n",
      "311 block6f_se_excite False\n",
      "312 block6f_project_conv False\n",
      "313 block6f_project_bn False\n",
      "314 block6f_drop False\n",
      "315 block6f_add False\n",
      "316 block6g_expand_conv False\n",
      "317 block6g_expand_bn False\n",
      "318 block6g_expand_activation False\n",
      "319 block6g_dwconv2 False\n",
      "320 block6g_bn False\n",
      "321 block6g_activation False\n",
      "322 block6g_se_squeeze False\n",
      "323 block6g_se_reshape False\n",
      "324 block6g_se_reduce False\n",
      "325 block6g_se_expand False\n",
      "326 block6g_se_excite False\n",
      "327 block6g_project_conv False\n",
      "328 block6g_project_bn False\n",
      "329 block6g_drop False\n",
      "330 block6g_add False\n",
      "331 block6h_expand_conv False\n",
      "332 block6h_expand_bn False\n",
      "333 block6h_expand_activation False\n",
      "334 block6h_dwconv2 False\n",
      "335 block6h_bn False\n",
      "336 block6h_activation False\n",
      "337 block6h_se_squeeze False\n",
      "338 block6h_se_reshape False\n",
      "339 block6h_se_reduce False\n",
      "340 block6h_se_expand False\n",
      "341 block6h_se_excite False\n",
      "342 block6h_project_conv False\n",
      "343 block6h_project_bn False\n",
      "344 block6h_drop False\n",
      "345 block6h_add False\n",
      "346 block6i_expand_conv False\n",
      "347 block6i_expand_bn False\n",
      "348 block6i_expand_activation False\n",
      "349 block6i_dwconv2 False\n",
      "350 block6i_bn False\n",
      "351 block6i_activation False\n",
      "352 block6i_se_squeeze False\n",
      "353 block6i_se_reshape False\n",
      "354 block6i_se_reduce False\n",
      "355 block6i_se_expand False\n",
      "356 block6i_se_excite False\n",
      "357 block6i_project_conv False\n",
      "358 block6i_project_bn False\n",
      "359 block6i_drop False\n",
      "360 block6i_add False\n",
      "361 block6j_expand_conv False\n",
      "362 block6j_expand_bn False\n",
      "363 block6j_expand_activation False\n",
      "364 block6j_dwconv2 False\n",
      "365 block6j_bn False\n",
      "366 block6j_activation False\n",
      "367 block6j_se_squeeze False\n",
      "368 block6j_se_reshape False\n",
      "369 block6j_se_reduce False\n",
      "370 block6j_se_expand False\n",
      "371 block6j_se_excite False\n",
      "372 block6j_project_conv False\n",
      "373 block6j_project_bn False\n",
      "374 block6j_drop False\n",
      "375 block6j_add False\n",
      "376 block6k_expand_conv False\n",
      "377 block6k_expand_bn False\n",
      "378 block6k_expand_activation False\n",
      "379 block6k_dwconv2 False\n",
      "380 block6k_bn False\n",
      "381 block6k_activation False\n",
      "382 block6k_se_squeeze False\n",
      "383 block6k_se_reshape False\n",
      "384 block6k_se_reduce False\n",
      "385 block6k_se_expand False\n",
      "386 block6k_se_excite False\n",
      "387 block6k_project_conv False\n",
      "388 block6k_project_bn False\n",
      "389 block6k_drop True\n",
      "390 block6k_add True\n",
      "391 block6l_expand_conv True\n",
      "392 block6l_expand_bn True\n",
      "393 block6l_expand_activation True\n",
      "394 block6l_dwconv2 True\n",
      "395 block6l_bn True\n",
      "396 block6l_activation True\n",
      "397 block6l_se_squeeze True\n",
      "398 block6l_se_reshape True\n",
      "399 block6l_se_reduce True\n",
      "400 block6l_se_expand True\n",
      "401 block6l_se_excite True\n",
      "402 block6l_project_conv True\n",
      "403 block6l_project_bn True\n",
      "404 block6l_drop True\n",
      "405 block6l_add True\n",
      "406 top_conv True\n",
      "407 top_bn True\n",
      "408 top_activation True\n"
     ]
    }
   ],
   "source": [
    "loaded_saved_model.layers[1].trainable = True\n",
    "for i, layer in enumerate(loaded_saved_model.layers[1].layers[:-20]):\n",
    "    layer.trainable = False\n",
    "for i, layer in enumerate(loaded_saved_model.layers[1].layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                  patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "1105/1105 [==============================] - 722s 642ms/step - loss: 0.5980 - accuracy: 0.7921 - val_loss: 0.6641 - val_accuracy: 0.7769\n",
      "Epoch 7/100\n",
      "1105/1105 [==============================] - 710s 642ms/step - loss: 0.5309 - accuracy: 0.8166 - val_loss: 0.6522 - val_accuracy: 0.7846\n",
      "Epoch 8/100\n",
      "1105/1105 [==============================] - 709s 642ms/step - loss: 0.4644 - accuracy: 0.8398 - val_loss: 0.6457 - val_accuracy: 0.7859\n",
      "Epoch 9/100\n",
      "1105/1105 [==============================] - 710s 642ms/step - loss: 0.4030 - accuracy: 0.8611 - val_loss: 0.6580 - val_accuracy: 0.7871\n",
      "Epoch 10/100\n",
      "1105/1105 [==============================] - 709s 641ms/step - loss: 0.3377 - accuracy: 0.8829 - val_loss: 0.6725 - val_accuracy: 0.7911\n",
      "Epoch 11/100\n",
      "1105/1105 [==============================] - 713s 645ms/step - loss: 0.2824 - accuracy: 0.9022 - val_loss: 0.6688 - val_accuracy: 0.7984\n"
     ]
    }
   ],
   "source": [
    "loaded_saved_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              metrics=['accuracy'])\n",
    "history_14_fine_tune = loaded_saved_model.fit(train_data, epochs = 100,\n",
    "                                initial_epoch = history_101_food_classes_feature_extract.epoch[-1] + 1,\n",
    "                                validation_data = test_data,\n",
    "                                steps_per_epoch = len(train_data),\n",
    "                                validation_steps = int(0.2*len(test_data)),\n",
    "                                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474/474 [==============================] - 270s 569ms/step - loss: 0.6986 - accuracy: 0.7963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6985512971878052, 0.7963036298751831]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_saved_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujjwal/miniconda3/envs/tf2.15/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "loaded_saved_model.save(\"cuisine_79_6.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
